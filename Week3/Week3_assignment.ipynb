{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "spam_data = pd.read_csv('spam.csv')\n",
    "\n",
    "spam_data['target'] = np.where(spam_data['target']=='spam',1,0)\n",
    "spam_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(spam_data['text'], \n",
    "                                                    spam_data['target'], \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_one():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    spam_count = np.bincount(spam_data['target'])[1]\n",
    "    total_count = np.bincount(spam_data['target'])[0]+np.bincount(spam_data['target'])[1]\n",
    "    ratio = spam_count / total_count\n",
    "    return ratio * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def answer_two():\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    vect = CountVectorizer()\n",
    "    X_train_vect = vect.fit_transform(X_train)\n",
    "    feature_names = np.array(vect.get_feature_names())\n",
    "    length_tokens = []\n",
    "    for i in range(len(feature_names)):\n",
    "        length_tokens.append(len(feature_names[i]))\n",
    "    length_tokens.sort()\n",
    "    length_longest_token = length_tokens[-1]\n",
    "    for i in range(len(feature_names)):\n",
    "        if len(feature_names[i]) == length_longest_token:\n",
    "            longest_word = feature_names[i]\n",
    "    \n",
    "    return longest_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_two()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def answer_three():\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    vect = CountVectorizer()\n",
    "    X_train_vect = vect.fit_transform(X_train)\n",
    "    model = MultinomialNB(alpha = 0.1)\n",
    "    model.fit(X_train_vect, y_train)\n",
    "    predictions = model.predict(vect.transform(X_test))\n",
    "    score = roc_auc_score(y_test, predictions)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_three()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def answer_four():\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "    vect_tfidf = TfidfVectorizer()\n",
    "    X_train_tfidf = vect_tfidf.fit_transform(X_train)\n",
    "    feature_names_tfidf = np.array(vect_tfidf.get_feature_names())\n",
    "    sorted_tfidf_index = X_train_tfidf.max(0).toarray()[0].argsort()\n",
    "    smallest_tfidf = feature_names_tfidf[sorted_tfidf_index[:20]]\n",
    "    largest_tfidf = feature_names_tfidf[sorted_tfidf_index[:-21:-1]]\n",
    "    new_list = X_train_tfidf.max(0).toarray()[0]\n",
    "    smallest_val_tfidf = np.sort(new_list)[:20]\n",
    "    largest_val_tfidf = np.sort(new_list)[:-21:-1]\n",
    "    series1 = pd.Series(smallest_val_tfidf, index = smallest_tfidf)\n",
    "    series2 = pd.Series(largest_val_tfidf, index = largest_tfidf)\n",
    "    return (series1.sort_index(), series2.sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_four()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_five():\n",
    "    \n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    vect = TfidfVectorizer(min_df = 3).fit(X_train)\n",
    "    X_train_vect = vect.transform(X_train)\n",
    "\n",
    "    model  = MultinomialNB(alpha = 0.1)\n",
    "    model.fit(X_train_vect, y_train)\n",
    "\n",
    "    predictions = model.predict(vect.transform(X_test))\n",
    "    score_new = roc_auc_score(y_test, predictions)\n",
    "    return score_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_five()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_six():\n",
    "    doc_len = []\n",
    "    count = 0\n",
    "    for i in range(len(spam_data[spam_data['target'] == 1])):\n",
    "        doc_len.append(len(spam_data[spam_data['target'] == 1]['text'].iloc[i]))\n",
    "        count = count + doc_len[i]\n",
    "    avrg_spam = count/len(spam_data[spam_data['target']==1])\n",
    "    doc_len_nospam = []\n",
    "    count_nospam = 0\n",
    "    for i in range(len(spam_data[spam_data['target'] == 0])):\n",
    "        doc_len_nospam.append(len(spam_data[spam_data['target'] == 0]['text'].iloc[i]))\n",
    "        count_nospam = count_nospam + doc_len_nospam[i]\n",
    "    avrg_no_spam = count_nospam/len(spam_data[spam_data['target']==0])  \n",
    "    \n",
    "    return (avrg_no_spam, avrg_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_six()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature(X, feature_to_add):\n",
    "    \"\"\"\n",
    "    Returns sparse feature matrix with added feature.\n",
    "    feature_to_add can also be a list of features.\n",
    "    \"\"\"\n",
    "    from scipy.sparse import csr_matrix, hstack\n",
    "    return hstack([X, csr_matrix(feature_to_add).T], 'csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def answer_seven():\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    spam_data['new_feature'] = 0\n",
    "    for i in range(len(spam_data)):        \n",
    "        spam_data['new_feature'][i] = len(spam_data['text'][i])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(spam_data[['text', 'new_feature']],\n",
    "                                                        spam_data['target'],\n",
    "                                                        random_state = 0)\n",
    "    vect = TfidfVectorizer(min_df = 5)\n",
    "    vect.fit(X_train['text'])\n",
    "    X_vect_train = vect.transform(X_train['text'])\n",
    "    add_feature(X_vect_train, X_train['new_feature'])\n",
    "    model = SVC(C = 10000).fit(add_feature(X_vect_train, X_train['new_feature']), y_train)\n",
    "    predictions = model.predict(add_feature(vect.transform(X_test['text']), X_test['new_feature']))\n",
    "    score_auc = roc_auc_score(y_test, predictions)\n",
    "    return score_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_seven()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_eight():\n",
    "    import re\n",
    "    spam_data['nr_digit'] = 0\n",
    "    spam_data['nr_digit'] = spam_data['text'].str.count(r'\\d').tolist()\n",
    "    count_spam = 0\n",
    "    count_nospam = 0\n",
    "    for i in range(len(spam_data)):\n",
    "        if spam_data['target'][i] == 1:\n",
    "            count_spam = count_spam + spam_data['nr_digit'][i]\n",
    "        else:\n",
    "            count_nospam = count_nospam + spam_data['nr_digit'][i]\n",
    "    total_spam = len(spam_data[spam_data['target'] == 1])\n",
    "    total_nospam = len(spam_data[spam_data['target'] == 0])\n",
    "    avrg_dig_nospam = count_nospam / total_nospam\n",
    "    avrg_dig_spam = count_spam / total_spam\n",
    "    return (avrg_dig_nospam, avrg_dig_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_eight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_nine():\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    import re\n",
    "    spam_data['nr_digit'] = 0\n",
    "    spam_data['nr_digit'] = spam_data['text'].str.count(r'\\d').tolist()\n",
    "    count_spam = 0\n",
    "    count_nospam = 0\n",
    "    for i in range(len(spam_data)):\n",
    "        if spam_data['target'][i] == 1:\n",
    "            count_spam = count_spam + spam_data['nr_digit'][i]\n",
    "        else:\n",
    "            count_nospam = count_nospam + spam_data['nr_digit'][i]\n",
    "    spam_data['new_feature'] = 0\n",
    "    for i in range(len(spam_data)):        \n",
    "        spam_data['new_feature'][i] = len(spam_data['text'][i])\n",
    "    \n",
    "    avrg_digit_number = (count_spam + count_nospam) / (len(spam_data))\n",
    "    spam_data['new_feature2'] = avrg_digit_number\n",
    "    X_train, X_test, y_train, y_test = train_test_split(spam_data[['text', 'new_feature', 'new_feature2']],\n",
    "                                                        spam_data['target'],\n",
    "                                                        random_state = 0)\n",
    "    vect = TfidfVectorizer(min_df = 5, ngram_range = (1,3))\n",
    "    vect.fit(X_train['text'])\n",
    "    X_vect_train = vect.transform(X_train['text'])\n",
    "    new_X_train = add_feature(X_vect_train, X_train['new_feature'])\n",
    "    add_feature(new_X_train, X_train['new_feature2'])\n",
    "    new_X_test = add_feature(vect.transform(X_test['text']), X_test['new_feature'])\n",
    "    model = LogisticRegression(C = 100).fit(add_feature(new_X_train, X_train['new_feature2']), y_train)\n",
    "    predictions = model.predict(add_feature(new_X_test, X_test['new_feature2']))\n",
    "    score_auc = roc_auc_score(y_test, predictions)\n",
    "    return score_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_nine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_ten():\n",
    "    spam_data['nr_noword'] = 0\n",
    "    spam_data['nr_noword'] = spam_data['text'].str.count(r'\\W').tolist()\n",
    "    count_spam_noword = 0\n",
    "    count_nospam_noword = 0\n",
    "    for i in range(len(spam_data)):\n",
    "        if spam_data['target'][i] == 1:\n",
    "            count_spam_noword = count_spam_noword + spam_data['nr_noword'][i]\n",
    "        else:\n",
    "            count_nospam_noword = count_nospam_noword + spam_data['nr_noword'][i]\n",
    "    total_spam_noword = len(spam_data[spam_data['target'] == 1])\n",
    "    total_nospam_noword = len(spam_data[spam_data['target'] == 0])\n",
    "    avrg_nw_nospam = count_nospam_noword / total_nospam_noword\n",
    "    avrg_nw_spam = count_spam_noword / total_spam_noword\n",
    "    return (avrg_nw_nospam, avrg_nw_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_ten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_eleven():\n",
    "    \n",
    "    \n",
    "    return #Your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_eleven()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
